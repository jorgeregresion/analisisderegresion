#####MODELO DE REGRESION LINEAL MULTIPLE######

capa <-c(4330, 5500, 5500, 4700, 5200, 5500, 4700, 5500, 5800, 5000)  #Independiente (x2)
calidad <- c(2, 3, 4, 3, 4, 4, 4, 5, 5, 5) #Independiente (x1)
precio <- c(190, 219, 249, 249, 250, 340, 289, 395, 439, 525) #Dependiente (y)
plot(capa,precio,pch=12,xlab="capa",ylab="precio",main="grafica de dispersion",col="blue")
cor(precio,capa,method="pearson")
cor.test(precio,capa,method="pearson")
##con estos indicadores rechazamos el modelo simple
##ahora revisamos con la otra variable que tenemos
plot(calidad,precio,pch=11,xlab="capa",ylab="precio",main="grafica de dispersion",col="blue")
cor(precio,calidad,method="pearson")
cor.test(precio,calidad,method="pearson")
##comparacion de modelos
##pretendemos seleccionar al mejor subconjunto de variables independientes
##en este caso para la aplicacion del MRM tenemos dos variables independientes
##calidad y capacidad por lo que se propone 
##comprar tres modelos con la finalidad de aplicar el principio de parsimonia
##es decir, que se tienen muchas variables intentando explicar el modelo
##ante estas variables se pueden comparar tres modelos
#1)precio~capacidad
#2)precio~calidad
#3)precio~calidad+capacidad
##### COMO SELECCIONAMOS EL MEJOR MODELO  ###
##criterio de la informacion de Akaike(AIC)
##el problema de utilizar R-cudrada para comparar modelos es que al introducir 
##nuevas variables al modelo, esta medida siempre crece
##si estamos decidiendo cual de todos los modelos ajusta mejor a los datos,
##el modelo con mas variables independientes siempre sera el mejor ajustado
##por eso se utiliza el AIC, una medida de ajuste que penaliza el modelo
##por tener mas variables
##esta definido por AIC=(n)(log(SCR/n))+2k
##SCR=suma de cuadrados residuales
##k numero de variables independientes
##el problema es que el unico criterio para el AIC esi su valor es mayor el modelo es malo
##si el AIC es mejor el modelo es mejor
##el AIC nos va a ayudar a decidir sobre un modelo
####  el metodo mas recomendado es el metodo step by step
##para R se utiliza la funcion step()
##adento del metodo de step by step hay tres modalidades
##1) forward: parte del coeficiente Bo y de ahí va probando las variables
## independientes para ver cual es la que mas aporta al modelo
##2) backward: R empieza con todas las v.i. y estudi si el AIC baja 
## cuando hay cambios de variables
##3) both: empieza como el forward la diferencia es que se realizan test
## para conocer el var indep menos util
####  el metodo mas recomendable es el backward    #####
#*porque tiene un efecto represor que permite probar cuando una variable tiene
#*influencia solo si otra var se mantiene constante
###vamos a calcular el modelo para tres variables
moch<-data.frame(precio,capa,calidad)
cor(moch,use="everything",method="pearson")
mod1<-lm(precio~capa+calidad,data=moch)
summary(mod1)
step(mod1,direction="backward")
step(mod1,direction="both")
step(mod1,direction="forward")


##########
mod2 <- lm(precio~calidad, data =moch)
#Aplicar supuestos para comprobar si tenemos un buen modelo
moch$ajus <- fitted(mod2)
moch$resi <- residuals(mod2)
moch$rstud <- rstudent(mod2)

###Supuesto 1, NORMALIDAD
install.packages("lmtest")
require(lmtest)
ks.test(moch$rstud, "pnorm")
#HISTOGRAMA
hist(moch$rstud, xlab="residuales", main="Hist residuales")

###Supuesto 2, HOMOGENEIDAD DE VARIANZAS
bptest(mod2, studentize= FALSE, data=moch)
#p-value=0.4154>.05 -> la varianza es constante a lo largo de las pruebas

###Supuesto 3, DE AUTOCORRELACIÓN
dwtest(mod2, alternative="two.sided", data=moch)
#p-value=0.2976>.05 -> no existe correlación entre los residuos


## 0) analizar graficos de dispersion y pruebas de correlacion
## 1) plantear la ecuacion estimada origina, es decir con todas las variables
## 2) analizar la anova, r cuadrada, estadistico F (mediante p.h.)
## 3) comparen modelos ccon backward y analicen el modelo qyue genere la funcion step


y <-c(25.5, 31.2, 25.9, 38.4, 18.4, 26.7, 26.4,25.9,32,25.2,39.7,35.7,26.5)
x1<-c(1.74,6.32,6.2,10.52,1.19,1.22,4.10,6.32,4.08,4.15,10.15,1.72,1.70)
x2<-c( 5.30,5.42,8.41,4.63,11.60,5.85,6.62,8.72,4.42,7.60,4.83,3.12,5.3)
x3<-c( 10.8,9.4,7.2,8.5,9.4,9.9,8,9.1,8.7,9.2,9.4,7.6,8.2)
ejercicio<- data.frame(y, x1, x2,x3)
plot(x1,y,pch=12,xlab="x1",ylab="y",main="ejercicio",col="blue")
cor(y,x1,method="pearson")
cor.test(y,x1,method="pearson")
plot(x2,y,pch=12,xlab="x2",ylab="y",main="ejercicio",col="blue")
cor(y,x2,method="pearson")
cor.test(y,x2,method="pearson")
plot(x3,y,pch=12,xlab="x3",ylab="y",main="ejercicio",col="blue")
cor(y,x3,method="pearson")
cor.test(y,x3,method="pearson")
## correlacion  de x1=.65,x2=-.78,x3=-.18, como la correlacion con x3
## es cercana a 0, tiene una relacion pequeña con y
modmo <- lm(y~x1+x2+x3)
summary(modmo)
anova(modmo)
## el resultado de Mean Sq (ANOVA)=4.291
## el p-value=.00004464<.05
## el valor de F=31.04>1
## entonces tenemos un buen modelo
y=39.1767+1.0166x1-1.8608x2-.3461x3
step(modmo,direction="backward")
## de acuerdo AIC nos sugiere eliminar la variable x3
ejercicio1<- data.frame(y, x1, x2)
plot(x1,y,pch=12,xlab="x1",ylab="y",main="ejercicio",col="blue")
cor(y,x1,method="pearson")
cor.test(y,x1,method="pearson")
modmo1 <- lm(y~x1+x2)
summary(modmo1)
y=36.0888+1.0310x1-1.8688x2
anova(modmo1) ##vemos Mean Sq cercana a 0
## el resultado de Mean Sq (ANOVA)=3.997
## el p-value=.000006319<.05
## el valor de F=49.81>1
## entonces tenemos un mejor modelo, ya que la media de los residuales es mas cercana a 0
